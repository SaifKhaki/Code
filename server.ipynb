{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "import threading\n",
    "import yaml\n",
    "import io\n",
    "import math\n",
    "# ML Specific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read YAML file\n",
    "with open(\"config.yaml\", 'r') as stream:\n",
    "    config_loaded = yaml.safe_load(stream)\n",
    "\n",
    "# reading from config file\n",
    "port = config_loaded[\"server\"][\"port\"]\n",
    "datasets = config_loaded[\"datasets\"]\n",
    "s_nodes_count = config_loaded[\"kazaa\"][\"s_nodes\"]\n",
    "o_nodes_count = config_loaded[\"kazaa\"][\"o_node_per\"]\n",
    "all_nodes = s_nodes_count + (s_nodes_count*o_nodes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global fields\n",
    "lock = threading.Lock()\n",
    "clientId = -1\n",
    "threadCount = 0\n",
    "node_threads = [None]*all_nodes\n",
    "ports = []\n",
    "ips = []\n",
    "download_speed = [0]*all_nodes\n",
    "gpu_ram_free = [0]*all_nodes\n",
    "ram_free = [0]*all_nodes\n",
    "cpu_free = [0]*all_nodes\n",
    "cpu_cores = [0]*all_nodes\n",
    "status = ['']*all_nodes\n",
    "kazaa_constant = [0]*all_nodes\n",
    "# format: snode_(ip,port,connection_object) as key : [(ip,port,connection)i] for i=onode_count as value \n",
    "network = {}\n",
    "\n",
    "######################################## Connections ################################\n",
    "# format: [connection_objects] for all nodes\n",
    "connections = []\n",
    "# format: [(ip, port, connection_object)i] for i = snode_count\n",
    "snode_connections = []\n",
    "node_connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The server's IP address:  192.168.0.120\n"
     ]
    }
   ],
   "source": [
    "# giving a dynamic IP and reuseable port to the server\n",
    "port += 1\n",
    "node_connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "node_connection.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "host = socket.gethostname()\n",
    "print(\"The server's IP address: \", socket.gethostbyname(host))\n",
    "try:\n",
    "    node_connection.bind((host, port))\n",
    "except socket.error as e:\n",
    "    print(str(e))\n",
    "node_connection.listen(all_nodes)\n",
    "\n",
    "# Write server host to config.yaml file\n",
    "config_loaded[\"server\"][\"ip\"] = socket.gethostbyname(host)\n",
    "config_loaded[\"server\"][\"port\"] = port\n",
    "with io.open('config.yaml', 'w', encoding='utf8') as outfile:\n",
    "    yaml.dump(config_loaded, outfile, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# socket send consistent method \n",
    "# it sends the string, waits for the length of string client received, compares this length to the actual length. If both are equal\n",
    "# it sends ack else, it resends the same txt again.\n",
    "def socket_send(connection, txt):\n",
    "    ack = False\n",
    "    print(\">>sending\",txt+\"...\")\n",
    "    while(not ack):\n",
    "        connection.send(str.encode(txt))\n",
    "        len_txt = int(connection.recv(1024).decode('utf-8'))\n",
    "        if len_txt == len(txt):\n",
    "            connection.send(str.encode(\"ack\"))\n",
    "            ack = True\n",
    "        else:\n",
    "            connection.send(str.encode(\"resending\"))\n",
    "\n",
    "# socket receive consistent method \n",
    "# it receives the string, then sends its size back to the server and then it waits for an acknowledgement, If ack is received it \n",
    "# breaks out of the loop\n",
    "def socket_rcv(connection, size=1024):\n",
    "    ack = False\n",
    "    while(not ack):\n",
    "        txt = connection.recv(size).decode('utf-8')\n",
    "        connection.send(str.encode(str(len(txt))))\n",
    "        ack = True if connection.recv(size).decode('utf-8') == \"ack\" else False\n",
    "    print(\">>received\", txt+\"...\")\n",
    "    return txt\n",
    "    \n",
    "# giving minimum requirement of RAM for supernode\n",
    "def get_required_ram(fileSize, node=\"s\"):\n",
    "    amount = fileSize/s_nodes_count\n",
    "    if(node == \"o\"):\n",
    "        amount /= o_nodes_count\n",
    "    return amount\n",
    "        \n",
    "# calculating kazaa constant on the basis of which we are going to classify who is going to be a supernode or ordinary node\n",
    "def cal_kazaa_constant(id):\n",
    "    data_per_region = get_required_ram(size)\n",
    "    # /10 means to get data downloaded in max 10 secs\n",
    "    bytes_ps = data_per_region/10\n",
    "    kazaa_constant[id] = (((gpu_ram_free[id]+ram_free[id] >= data_per_region)*0.5)\n",
    "                          +(1 if (download_speed[id]/bytes_ps) >= 1 else (download_speed[id]/bytes_ps))*0.2\n",
    "                          +((gpu_ram_free[id]/(max(gpu_ram_free) if max(gpu_ram_free) != 0 else 1))*0.15)\n",
    "                          +((ram_free[id]/(max(ram_free) if max(ram_free) != 0 else 1))*0.075)\n",
    "                          +((cpu_free[id]/100)*0.05)\n",
    "                          +(1 if (cpu_cores[id]/8)>=1 else (cpu_cores[id]/8)*0.025)\n",
    "                          )\n",
    "\n",
    "# classifying nodes into supernode or ordinary node\n",
    "def get_node_status(id):\n",
    "    const = kazaa_constant[id]\n",
    "    a = kazaa_constant.copy()\n",
    "    a.sort()\n",
    "    if const in a[len(a)-s_nodes_count:]:\n",
    "        return \"s\"\n",
    "    else:\n",
    "        return \"o\"\n",
    "\n",
    "# assigning onodes to supernodes\n",
    "def create_network():\n",
    "    d2_lst = []\n",
    "    for i in range(len(ports)):\n",
    "        lst = [ips[i], ports[i], status[i], kazaa_constant[i], connections[i]]\n",
    "        d2_lst.append(lst)\n",
    "    \n",
    "    headers = ['IP', 'Port', 'Status', 'Kazaa Constant', 'Connection']\n",
    "    df = pd.DataFrame(d2_lst, columns = headers)\n",
    "    df = df.sort_values(by='Kazaa Constant', ascending=False)\n",
    "    \n",
    "    i = 0\n",
    "    for index1, row1 in df[:s_nodes_count].iterrows():\n",
    "        network[(row1['IP'], row1['Port'], row1['Connection'])] = []\n",
    "        start = df.shape[0] - o_nodes_count*(i+1)\n",
    "        end = df.shape[0] - o_nodes_count*i\n",
    "        for index2, row2 in df[start:end].iterrows():\n",
    "            network[(row1['IP'], row1['Port'], row1['Connection'])].append((row2['IP'], row2['Port'], row2['Connection']))\n",
    "        i+=1\n",
    "\n",
    "# initiating formation of kazaa architecture\n",
    "def initiate_kazaa():\n",
    "    for i in range(len(connections)):\n",
    "        cal_kazaa_constant(i)\n",
    "    \n",
    "    print(\"Constants calculated are: \", kazaa_constant)\n",
    "    \n",
    "    for i in range(len(connections)):\n",
    "        status[i] = get_node_status(i)\n",
    "        \n",
    "    print(\"Statuses calculated are: \", status)\n",
    "        \n",
    "    for connection in connections:\n",
    "        send_str = \"status:\" + status[connections.index(connection)]\n",
    "        socket_send(connection, send_str)\n",
    "        send_str = \"k_const:\" + str(kazaa_constant[connections.index(connection)])\n",
    "        socket_send(connection, send_str)\n",
    "    \n",
    "    # creating a network topology as in kazaa\n",
    "    create_network()\n",
    "    \n",
    "    for (sIP, sPort, sConnection), onodes in network.items():\n",
    "        onodes_IP_PORTS_to_send = len(onodes)\n",
    "        snode_connections.append((sIP, sPort, sConnection))\n",
    "        print(\"waiting to receive snodes ip to be shared among its region ordinary nodes...\")\n",
    "        ip_port = socket_rcv(sConnection).split(\":\")\n",
    "        send_snode_IP_PORT = ip_port[0] + \":\" + ip_port[1]\n",
    "        print(\"rcvd: \" + send_snode_IP_PORT)\n",
    "        for (oIP, oPort, oConnection) in onodes:\n",
    "            socket_send(oConnection, send_snode_IP_PORT)\n",
    "\n",
    "# cleaning the text of mails with respect to a tockenizer\n",
    "def clean_str(string, reg = RegexpTokenizer(r'[a-z]+')):\n",
    "    string = string.lower()\n",
    "    tokens = reg.tokenize(string)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def send_rows_snode(connection, df, div, index, headers):\n",
    "    socket_send(connection, \"rcv:\"+str(div))\n",
    "    socket_send(connection, \"rcv:\"+headers)\n",
    "    for i, row in df[int(div*index):int(div*(index+1))].iterrows():\n",
    "        socket_send(connection, str(row[0])+\":\"+str(row[1])+\":\"+str(row[2])+\":\"+str(row[3]))\n",
    "        ack = socket_rcv(connection)\n",
    "        while(ack != \"rcvd\"):\n",
    "            socket_send(connection, str(row[0])+\":\"+str(row[1])+\":\"+str(row[2])+\":\"+str(row[3]))\n",
    "            ack = socket_rcv(connection)\n",
    "\n",
    "# division, sending of dataset to supernodes\n",
    "def ensemble_distribution():\n",
    "    df = pd.read_csv('spam_ham_dataset.csv')\n",
    "    df['text_clean'] = df['text'].apply(lambda string: clean_str(string))\n",
    "    del df['text']\n",
    "    \n",
    "    # data per supernode\n",
    "    division = math.ceil(df.shape[0]/s_nodes_count)\n",
    "    \n",
    "    # headers\n",
    "    headers = \":\".join(list(df.columns))\n",
    "    \n",
    "    index = 0\n",
    "    print(\"Sending data...\")\n",
    "    for snode_connection in snode_connections:\n",
    "        send_rows_snode(snode_connection[2], df, division, index, headers)\n",
    "        print(\"Sent all data to\", snode_connection[0], \"at port\", snode_connection[1])\n",
    "        index += 1\n",
    "    \n",
    "# function to be run in independent thread\n",
    "def multi_threaded_client(connection, id):\n",
    "    socket_send(connection, 'Server is working:')\n",
    "    \n",
    "    # receiving system info\n",
    "    data = socket_rcv(connection)\n",
    "    if data.startswith(\"rcv:\"):\n",
    "        count = int(data[len(\"rcv:\"):])\n",
    "        if(count == 5):\n",
    "            download_speed[id] = float(socket_rcv(connection)[len(\"dsp:\"):])\n",
    "            gpu_ram_free[id] = float(socket_rcv(connection)[len(\"gpu:\"):])\n",
    "            ram_free[id] = float(socket_rcv(connection)[len(\"ram:\"):])\n",
    "            cpu_free[id] = float(socket_rcv(connection)[len(\"cpu:\"):])\n",
    "            cpu_cores[id] = int(socket_rcv(connection)[len(\"cor:\"):])\n",
    "\n",
    "            # sending ack\n",
    "            send_str = \"ack: received following system info:  \\nDownload_speed = \" + str(download_speed[id]) + \"B \\nFree_GPU_RAM = \" + str(gpu_ram_free[id]) + \"B \\nFree_RAM = \" + str(ram_free[id]) + \"B \\nFree_CPU = \" + str(cpu_free[id]) + \" \\nCPU_Cores = \" + str(cpu_cores[id])\n",
    "            socket_send(connection, send_str)\n",
    "    lock.acquire()\n",
    "    connections.append(connection)\n",
    "    lock.release()\n",
    "    \n",
    "    # creates a nerwork of supernodes and ordinary nodes, and introduce them to each other\n",
    "    if(len(connections) >= all_nodes):\n",
    "        initiate_kazaa()\n",
    "        # division, sending of dataset to supernodes, receiving predictions\n",
    "        ensemble_distribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming dataset uploaded by the user\n",
    "fileNumber = int(input(\"Which dataset you want to use from 0 - \" + str(len(datasets)-1) + \" : \"))\n",
    "size = os.path.getsize(datasets[fileNumber]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Socket is listening..\n",
      ">>sendingThread Number: 1 - Connected to: 192.168.0.120:58130 \n",
      "Server is working:...\n",
      ">>received rcv:5...\n",
      ">>received dsp:1395920.8413602603...\n",
      ">>received gpu:0...\n",
      ">>received ram:9749917696...\n",
      ">>received cpu:77.3...\n",
      ">>received cor:4...\n",
      ">>sending ack: received following system info:  \n",
      "Download_speed = 1395920.8413602603B \n",
      "Free_GPU_RAM = 0.0B \n",
      "Free_RAM = 9749917696.0B \n",
      "Free_CPU = 77.3 \n",
      "CPU_Cores = 4...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-832ae3d72317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Socket is listening..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mclientId\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mIP\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maddress\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhostaddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Issue #7995: if no default timeout is set and the listening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# always open for more clients to connect\n",
    "print('Socket is listening..')\n",
    "while(True):\n",
    "    Client, address = node_connection.accept()\n",
    "    clientId += 1\n",
    "    \n",
    "    node_threads[threadCount] = threading.Thread(target = multi_threaded_client, args = (Client, clientId))\n",
    "    node_threads[threadCount].start()\n",
    "    \n",
    "    threadCount += 1\n",
    "    ips.append(address[0])\n",
    "    ports.append(address[1])\n",
    "    print('Thread Number: ' + str(threadCount) + \" - \" + 'Connected to: ' + address[0] + ':' + str(address[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}