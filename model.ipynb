{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('spam_ham_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id label  label_num                                         text_clean\n",
       "0      605   ham          0  subject enron methanol meter this is a follow ...\n",
       "1     2349   ham          0  subject hpl nom for january see attached file ...\n",
       "2     3624   ham          0  subject neon retreat ho ho ho we re around to ...\n",
       "3     4685  spam          1  subject photoshop windows office cheap main tr...\n",
       "4     2030   ham          0  subject re indian springs this deal is to book...\n",
       "...    ...   ...        ...                                                ...\n",
       "1995  1216   ham          0  subject re saudi arabia daren i ll follow up o...\n",
       "1996  1094   ham          0  subject july co owner s volumes july lst co ow...\n",
       "1997  5049  spam          1  subject greatly improve your stamina i ve been...\n",
       "1998  2467   ham          0  subject calpine daily gas nomination ricky a a...\n",
       "1999   592   ham          0  subject king ranch stella it is very important...\n",
       "\n",
       "[2000 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>label_num</th>\n      <th>text_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>605</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject enron methanol meter this is a follow ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2349</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject hpl nom for january see attached file ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3624</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject neon retreat ho ho ho we re around to ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4685</td>\n      <td>spam</td>\n      <td>1</td>\n      <td>subject photoshop windows office cheap main tr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2030</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject re indian springs this deal is to book...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>1216</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject re saudi arabia daren i ll follow up o...</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1094</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject july co owner s volumes july lst co ow...</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>5049</td>\n      <td>spam</td>\n      <td>1</td>\n      <td>subject greatly improve your stamina i ve been...</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>2467</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject calpine daily gas nomination ricky a a...</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>592</td>\n      <td>ham</td>\n      <td>0</td>\n      <td>subject king ranch stella it is very important...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def clean_str(string, reg = RegexpTokenizer(r'[a-z]+')):\n",
    "    string = string.lower()\n",
    "    tokens = reg.tokenize(string)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['text_clean'] = df['text'].apply(lambda string: clean_str(string))\n",
    "del df['text']\n",
    "df = df[:2000]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "n = [1,2,3,4,5]\n",
    "n[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df.text_clean)\n",
    "\n",
    "# Get the categories\n",
    "y = df.label\n",
    "\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  96.0\n"
     ]
    }
   ],
   "source": [
    "# Find the best hyperparameter with GridSearchCV\n",
    "# Exhaustive search over specified parameter values for an estimator.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"alpha\": [0.2,1,2,5,10], \"fit_prior\": [True, False]}\n",
    "\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid=parameters)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Create a DataFrame with the best Hyperparameters\n",
    "pd.DataFrame(grid.cv_results_)[['params','mean_test_score']]\\\n",
    "                               .sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "# Create the model with the best hyperparameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha, fit_prior = grid.best_params_['alpha'], grid.best_params_['fit_prior']\n",
    "model = MultinomialNB(alpha = alpha)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Accuracy: ', round(accuracy_score(y_test,y_pred),3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         ham       0.98      0.97      0.97       306\n        spam       0.90      0.94      0.92        94\n\n    accuracy                           0.96       400\n   macro avg       0.94      0.95      0.95       400\nweighted avg       0.96      0.96      0.96       400\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}